# Post 0: CAST: Corrigibility as Singular Target - Knowledge Analysis

## Background Knowledge
Prerequisites and existing concepts the author assumes familiarity with:

### AI Safety & Existential Risk
- The principal-agent problem from economics/game theory
- Omohundro's instrumental convergent drives (self-preservation, resource acquisition, goal stability)
- Misuse vs. mistake framing of AI risk
- The "acute risk period" concept
- Existential/catastrophic risk from misaligned superintelligent AI
- Value alignment problem

### Decision Theory & Agent Foundations
- Von Neumann-Morgenstern utility theory
- Expected utility maximization
- Utility functions and reward functions
- The distinction between terminal and instrumental goals
- Optimization and mesa-optimization

### Machine Learning & Training
- Reinforcement learning from human feedback (RLHF)
- Gradient descent and backpropagation
- Training distributions vs. out-of-distribution behavior
- Prosaic vs. non-prosaic AI methods
- Constitutional AI approach (Anthropic)

### Prior Corrigibility Literature
- MIRI 2015 Corrigibility paper (Soares, Fallenstein, Yudkowsky, Armstrong)
- Paul Christiano's corrigibility writings
- The shutdown problem / stop button problem
- Utility indifference as attempted solution
- Arbital pages on corrigibility (Yudkowsky)
- Alex Turner's work on power-seeking and attainable utility preservation

### Philosophical Concepts
- Coherent Extrapolated Volition (CEV)
- Value fragility ("Fragility of Value")
- The distinction between values/goals and beliefs/strategies
- Personhood and moral status questions

### Technical AI Concepts
- Simulators and simulacra (LLM behavior)
- Mechanistic interpretability
- Situational awareness in AI systems
- Distributional shift

## New Knowledge (Author's Novel Contributions)

### Core Novel Claims
1. **Corrigibility as unified simple concept**: The claim that obedience, conservatism, shutdownability, transparency, and low-impact all emerge from a single underlying generator property
2. **CAST as superior target**: The argument that training for corrigibility alone (as singular target) is safer than mixed goals or helpfulness+harmlessness+honesty
3. **Attractor basin hypothesis**: The proposal that partial corrigibility forms an attractor basin where semi-corrigible agents assist in becoming more corrigible
4. **Non-self-protection uniqueness**: The claim that corrigibility is nearly unique among useful goals for being simultaneously useful AND non-self-protective

### Novel Framings
- "Corrigibility is a target, not a technique" - architecture-agnostic nature
- Principal vs. user distinction for deployed systems
- Pure vs. impure corrigibility distinction
- Emergent corrigibility being insufficient (contra Paul Christiano)

### Original Arguments
- The argument that corrigibility's simplicity makes it more learnable than human values
- The claim that prosaic training might land within the corrigibility attractor basin
- The warning that current frontier labs are NOT training for corrigibility despite appearances
- The formalism attempt linking corrigibility to empowerment (later retracted)

### Methodological Contributions
- Emphasis on intuitive understanding before formalization
- The "Corrigibility Training Context" prompt for GPT
